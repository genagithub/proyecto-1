{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Quienes son los empleados con mayor riesgo de salida?\n",
    "Siendo un problema común, cada vez que un empleado se va se enfrenta un proceso largo y costoso, eso sumado luego al reclutamiento y capacitación para encontrar a alguien que lo reemplace. A continuación se identificarán los factores clave que contribuyen al cambio de rotación de personal y se extraerán resultados valiosos que sirvan para desarrollar estrategias efectivas y reducir los costos asociados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "df  = pd.read_csv(\"data/employee.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables categóricas y datasets desbalanceados\n",
    "La función de las variables categóricas es brindar información clasificando las observaciones, puenden demostrar una influencia en los datos permitiendonos determinar comportamientos o sacar conclusiones premeditadas si los datos influyen en estas. Los Trip_Priceos de variables categóricas que hay son nominales: aquellas que actúan como etiquetas de los objetos(dentro de estas pueden encontrarse las que se dividen en 2 clases y su codificación las convierte en binarias, es decir, valores posibles de 0 o 1) y ordinales: aquellas que representan un órden jerárquico en particular que rige en las observaciones.\n",
    "\n",
    "En algunos casos los datasets tienden a contener más cantidades de datos categóricos que otros, esto puede llegar a traer problemas la hora de entrenar un modelo o evaluar el desempeño de este debido a que la variable minoritaria tiende a ser ignorada y genera un sesgo en cuanto a la importancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_count = df[\"LeaveOrNot\"].value_counts().reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n", 
    "\n",
    "ax[0].bar(var_count[\"LeaveOrNot\"], var_count[\"count\"], color=[\"b\",\"orange\"])\n",
    "ax[0].grid(\"on\")\n",
    "ax[0].set_title(\"Conteo de clases\")\n",
    "ax[1].pie(var_count[\"count\"], labels=var_count[\"LeaveOrNot\"], autopct='%1.1f%%')\n",
    "ax[1].set_title(\"Proporciones de clases\")\n",
    "\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codificando a las variables categóricas nominales\n",
    "df_encoded = df.copy()\n",
    "df_encoded[[\"Education\",\"City\",\"Gender\",\"EverBenched\"]] = OrdinalEncoder().fit_transform(df[[\"Education\",\"City\",\"Gender\",\"EverBenched\"]])\n",
    "\n",
    "# a su vez generamos una versión decodificada de la variable objetivo\n",
    "map = {\n",
    "    0:\"permanece\",\n",
    "    1:\"sale\"\n",
    "}\n",
    "df[\"LeaveOrNot_txt\"] = df[\"LeaveOrNot\"].apply(lambda x : map.get(x))\n",
    "\n",
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CART(classification and regression trees)\n",
    "Algoritmos basados en calcular umbrales que determinen el resultado de una variable, de manera iterativa se generan particiones sobre la región de información hasta llegar a una formación de grupo lo más homogénea posible. Haciendo analogía a la estructura de un árbol, a partir de la raíz principal se extienden nodos adicionales que representan una condición y hojas que indican la pureza en su región de clases, de esta manera su trayectoria consiste en integorrantes de si o no junto con respuestas asociadas y la fiabilidad de estas. El modelado a partir de esta técnica de aprendizaje requiere controlar la complejidad del árbol de decisión, siendo la pre-poda la acción de limitar el crecimiento durante el proceso de entrenamiento y la post-poda lo mismo luego de este último, esto se realiza mediante la programación de valores númericos definidos y asignados por el usuario, es decir, un ajuste de hiperparámetros y aglunos ejemplos son definir la profundidad máxima o el mínimo número de muestras requeridas para cada partición o hoja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seccionando los datos en grupos de entrenamiento y prueba\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                                   df_encoded[df_encoded.columns[:-1]], # variables explicativas\n",
    "                                                   df_encoded[\"LeaveOrNot\"], # variable objetivo\n",
    "                                                   test_size=0.1) # tamaño de prueba pequeño\n",
    "\n",
    "# generando el árbol de clasificación\n",
    "tree_decision_clf = tree.DecisionTreeClassifier(criterion=\"entropy\", # medida de aleatoriedad, determinará los nodos del modelo en base a la probabilidad de clasificar erroneamente una variable, pero sin darle mayor importancias a ciertas características\n",
    "                                           max_depth=6, # distancia entre el nodo(condición) principal y la última hoja(respuesta asociada), valores recomendados: 3-10\n",
    "                                           min_samples_split=6, # mínimo número de muestras requeridas para dividir un nodo, valores recomendados: 2-10\n",
    "                                           min_samples_leaf=5, #  mínimo número de muestras requeridas en cada hoja, valores recomendados: 1-10\n",
    "                                           ccp_alpha=0.003) # valor de post-poda(luego de que el modelo se ajute) que evita el sobreajuste \n",
    "\n",
    "model = tree_decision_clf.fit(x_train, y_train)\n",
    "\n",
    "# clasificación de los datos de prueba\n",
    "\n",
    "class_predicts = model.predict(x_test)\n",
    "\n",
    "class_real = y_test.values\n",
    "\n",
    "# Matriz de confusión: recolecta los aciertos y desaciertos tanto de la clase postiva como negativa del modelo\n",
    "\n",
    "matrix_confusion = confusion_matrix(class_real,class_predicts)\n",
    "TP = matrix_confusion[0,0]\n",
    "FP = matrix_confusion[0,1]\n",
    "FN = matrix_confusion[1,0]\n",
    "TN = matrix_confusion[1,1]\n",
    "\n",
    "# Accuracy: indica la acertividad general de nuestro modelo con respecto a las nuevas observaciones\n",
    "\n",
    "accuracy = accuracy_score(class_real, class_predicts)\n",
    "color_accuracy = \"green\"\n",
    "if accuracy < 0.6:\n",
    "    color_accuracy = \"red\"\n",
    "accuracy_str = str(accuracy)\n",
    "\n",
    "# Recall: es utilizada para poder saber la efectividad de nuestro modelo a la hora de predecir valores de la clase positiva\n",
    "\n",
    "recall = recall_score(class_real, class_predicts)\n",
    "color_recall = \"green\"\n",
    "if recall < 0.6:\n",
    "    color_recall = \"red\"\n",
    "recall_str = str(recall)\n",
    "\n",
    "# Precision: es utilizada para poder saber que porcentage de valores que fueron clasificados como positivos son realmente positivos\n",
    "\n",
    "precision = precision_score(class_real, class_predicts)\n",
    "color_precision = \"green\"\n",
    "if precision < 0.6:\n",
    "    color_precision = \"red\"\n",
    "precision_str = str(precision)\n",
    "\n",
    "# F1 Score: es utilizada como un resumen de las dos últimas métricas\n",
    "\n",
    "F1_score = f1_score(class_real, class_predicts)\n",
    "color_f1 = \"green\"\n",
    "if F1_score < 0.6:\n",
    "    color_f1 = \"red\"\n",
    "F1_score_str = str(F1_score)\n",
    "\n",
    "# describiendo la estructura final del árbol\n",
    "plt.figure(figsize=(32,22))\n",
    "tree.plot_tree(model, feature_names=df_encoded.columns[:-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dashboard que compara probabilidades de salida juntos con medias y describe el desempeño del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creación de dashboard basado en la estructura HTML/CSS\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div(id=\"body\",className=\"e1_body\",children=[\n",
    "html.H1(\"Futuro de Empleados\",id=\"title\",className=\"e1_title\"),\n",
    "html.Div(className=\"e1_dashboards\",children=[\n",
    "    html.Div(id=\"graph_div_1\",className=\"e1_graph_div\",children=[\n",
    "        html.Div(id=\"dropdown_div_1\",className=\"e1_dropdown_div\",children=[\n",
    "            dcc.Dropdown(id=\"dropdown_1\",className=\"e1_dropdown\",\n",
    "                        options = [\n",
    "                            {\"label\":\"Educación\",\"value\":\"Education\"},\n",
    "                            {\"label\":\"Año de incorporación\",\"value\":\"JoiningYear\"},\n",
    "                            {\"label\":\"Ciudad\",\"value\":\"City\"},\n",
    "                            {\"label\":\"Género\",\"value\":\"Gender\"},\n",
    "                            {\"label\":\"Siempre en banca\",\"value\":\"EverBenched\"}\n",
    "                        ],\n",
    "                        value=\"Education\",\n",
    "                        multi=False,\n",
    "                        clearable=False)\n",
    "        ]),\n",
    "        dcc.Graph(id=\"piechart\",className=\"e1_graph\",figure={})\n",
    "    ]),\n",
    "    html.Div(id=\"graph_div_2\",className=\"e1_graph_div\",children=[\n",
    "        html.Div(id=\"dropdown_div_2\",className=\"e1_dropdown_div\",children=[\n",
    "            dcc.Dropdown(id=\"dropdown_2\",className=\"e1_dropdown\",\n",
    "                        options = [\n",
    "                            {\"label\":\"Edad\",\"value\":\"Age\"},\n",
    "                            {\"label\":\"Nivel de pago\",\"value\":\"PaymentTier\"},\n",
    "                            {\"label\":\"Experiencia en el dominio\",\"value\":\"ExperienceInCurrentDomain\"}\n",
    "                        ],\n",
    "                        value=\"Age\",\n",
    "                        multi=False,\n",
    "                        clearable=False)\n",
    "        ]),\n",
    "        dcc.Graph(id=\"bar\",className=\"e1_graph\",figure={})\n",
    "    ]),\n",
    "]),\n",
    "    \n",
    "    html.Div(className=\"e1_div\", children=[\n",
    "        html.Div(id=\"performance\", className=\"e1_performance\",children=[\n",
    "            html.P([html.B(\"Clases reales\", style={\"color\":\"blue\"}),\"   |   \",html.B(\"Predicciones\",style={\"color\":\"red\"})], style={\"text-align\":\"center\",\"font-family\":\"sans-serif\"}),\n",
    "            html.P(\"--------------------------------------------------------------------------------------------------------------------------------------\",style={\"margin\":\"0\"}),\n",
    "            html.P(f\"{class_real}\", className=\"e1_real_class\"),\n",
    "            html.P(f\"{class_predicts}\", className=\"e1_predicts\")\n",
    "        ]),\n",
    "        html.Div(id=\"metrics\", className=\"e1_metrics\", children=[\n",
    "                html.P(\"Matriz de confusión\", style={\"font-size\":\"0.9em\",\"text-align\":\"center\",\"font-family\":\"sans-serif\",\"font-weigth\":\"bold\"}),\n",
    "                html.Div(id=\"matrix\", className=\"e1_matrix\", children=[\n",
    "                html.Div([html.B(TP,style={\"color\":\"green\",\"font-family\":\"sans-serif\"})],id=\"TP\",className=\"e1_successes\"), \n",
    "                html.Div([html.B(FP,style={\"color\":\"red\",\"font-family\":\"sans-serif\"})],id=\"FP\",className=\"e1_mistakes\"),\n",
    "                html.Div([html.B(FN,style={\"color\":\"red\",\"font-family\":\"sans-serif\"})],id=\"FN\",className=\"e1_mistakes\"),\n",
    "                html.Div([html.B(TN,style={\"color\":\"green\",\"font-family\":\"sans-serif\"})],id=\"TN\",className=\"e1_successes\")\n",
    "                ]),\n",
    "                html.Div(id=\"scores\",children=[\n",
    "                html.Ul(id=\"list\",children=[\n",
    "                html.Li([f\"Accuracy: \",html.B(accuracy_str[:4],style={\"color\":f\"{color_accuracy}\"})],id=\"accuracy\",className=\"e1_score\"),\n",
    "                html.Li([f\"Recall: \",html.B(recall_str[:4],style={\"color\":f\"{color_recall}\"})],id=\"recall\",className=\"e1_score\"),\n",
    "                html.Li([f\"Precision: \",html.B(precision_str[:4],style={\"color\":f\"{color_precision}\"})],id=\"precision\",className=\"e1_score\"),\n",
    "                html.Li([f\"F1 Score: \",html.B(F1_score_str[:4],style={\"color\":f\"{color_f1}\"})],id=\"f1_score\",className=\"e1_score\")\n",
    "                ])\n",
    "                \n",
    "            ])\n",
    "        ])\n",
    "    ])\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    [Output(component_id=\"piechart\",component_property=\"figure\"),\n",
    "    Output(component_id=\"bar\",component_property=\"figure\")],\n",
    "    [Input(component_id=\"dropdown_1\",component_property=\"value\"),\n",
    "    Input(component_id=\"dropdown_2\",component_property=\"value\")]\n",
    ")\n",
    "\n",
    "def update_graph(slct_var_cat,slct_var_num):\n",
    "    \n",
    "    df[\"JoiningYear\"] = df[\"JoiningYear\"].astype(str)\n",
    "    df_percentage = df.groupby(slct_var_cat)[\"LeaveOrNot\"].mean().reset_index()\n",
    "    df_percentage[\"LeaveOrNot\"] = round(df_percentage[\"LeaveOrNot\"] * 100)\n",
    "    df_percentage[\"LeaveOrNot\"] = df_percentage[\"LeaveOrNot\"].astype(str)\n",
    "    df_percentage[\"var_percentage\"] = df_percentage[slct_var_cat].astype(str)+\"(\"+df_percentage[\"LeaveOrNot\"]+\"%)\"\n",
    "    \n",
    "    piechart = px.pie(df_percentage, values=\"LeaveOrNot\", names=\"var_percentage\", title=\"Probabilidad de salida\")\n",
    "    \n",
    "    df_mean = df.groupby(\"LeaveOrNot_txt\")[slct_var_num].mean().reset_index()\n",
    "    \n",
    "    barplot = px.bar(df_mean, x=\"LeaveOrNot_txt\", y=slct_var_num, title=\"Medias estadísticas\")\n",
    "    barplot.update_layout(xaxis_title=\" \", yaxis_title=\" \")\n",
    "    \n",
    "    return piechart,barplot\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
